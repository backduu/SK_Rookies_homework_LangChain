{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4b8ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ë¬¸ì œ 4-2 : ì¡°ê±´ë¶€ ë¶„ê¸°ê°€ ìˆëŠ” ë©”ë‰´ ì¶”ì²œ ì‹œìŠ¤í…œ ( LangGraph ì‚¬ìš©)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaea4d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List\n",
    "from langchain_core.messages import AIMessage, HumanMessage, BaseMessage\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph.message import MessageState\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])\n",
    "print(UPSTAGE_API_KEY[30:])\n",
    "print(TAVILY_API_KEY[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebebb5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        temperature=0.5\n",
    "    )\n",
    "print(llm)\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# llm = ChatOpenAI(\n",
    "#     model='gpt-3.5-turbo-0125', \n",
    "#     temperature=0,\n",
    "# )\n",
    "# print(llm.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70619182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë“œ ë° ë¶„í• \n",
    "\n",
    "loader = TextLoader(\"./data/cafe_menu.txt\", encoding=\"utf-8\")\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# ë²¡í„° DB ìƒì„± ë° ì €ì¥\n",
    "\n",
    "embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "db.save_local(\"./db/cafe_db_upstage\")\n",
    "\n",
    "print(\"ë²¡í„° DBê°€ './db/cafe_db_upstage' í´ë”ì— ì„±ê³µì ìœ¼ë¡œ ìƒì„± ë° ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e229e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector DB ë¬¸ì„œì—ì„œ êµ¬ì¡°í™”ëœ ì •ë³´ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜\n",
    "def parse_menu_doc(doc: Document) -> dict:\n",
    "    \"\"\"Vector DB ë¬¸ì„œì—ì„œ 'Key: Value' í˜•ì‹ì˜ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\"\"\"\n",
    "    info = {}\n",
    "    for line in doc.page_content.split('\\n'):\n",
    "        if ':' in line:\n",
    "            key, value = line.split(':', 1)\n",
    "            info[key.strip()] = value.strip()\n",
    "    return info\n",
    "\n",
    "# ì§ˆë¬¸ ìœ í˜•ì„ ë¶„ë¥˜í•˜ëŠ” í•¨ìˆ˜ (Router)\n",
    "def classify_question(state: MessageState) -> str:\n",
    "    \"\"\"ì‚¬ìš©ìì˜ ë§ˆì§€ë§‰ ë©”ì‹œì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ ìœ í˜•ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    user_message = state[\"messages\"][-1].content.lower()\n",
    "    \n",
    "    price_keywords = [\"ê°€ê²©\", \"ì–¼ë§ˆ\"]\n",
    "    recommend_keywords = [\"ì¶”ì²œ\", \"ì–´ë–¤ê²Œ\", \"ë­ê°€ ë§›ìˆ\", \"ì¸ê¸°\"]\n",
    "    \n",
    "    if any(keyword in user_message for keyword in price_keywords):\n",
    "        return \"price_inquiry\"\n",
    "    elif any(keyword in user_message for keyword in recommend_keywords):\n",
    "        return \"recommendation_request\"\n",
    "    else:\n",
    "        return \"menu_inquiry\"\n",
    "\n",
    "# ê° ë¬¸ì˜ ìœ í˜•ì„ ì²˜ë¦¬í•˜ëŠ” ë…¸ë“œ(Node) í•¨ìˆ˜ë“¤\n",
    "def handle_menu_inquiry(state: MessageState) -> dict:\n",
    "    \"\"\"ë©”ë‰´ ê´€ë ¨ ë¬¸ì˜ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.\"\"\"\n",
    "    user_message = state[\"messages\"][-1].content\n",
    "    # ì˜ë¯¸ë¡ ì  ê²€ìƒ‰: ì‚¬ìš©ì ë©”ì‹œì§€ ì§ì ‘ í™œìš©\n",
    "    docs = menu_db.similarity_search(user_message, k=1)\n",
    "    \n",
    "    if not docs:\n",
    "        response = \"ì£„ì†¡í•©ë‹ˆë‹¤, ë¬¸ì˜í•˜ì‹  ë©”ë‰´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    else:\n",
    "        info = parse_menu_doc(docs[0])\n",
    "        response = (\n",
    "            f\"âœ… {info.get('ë©”ë‰´', 'ì´ë¦„ ì—†ìŒ')}ì— ëŒ€í•œ ì •ë³´ì…ë‹ˆë‹¤:\\n\"\n",
    "            f\" - ê°€ê²©: {info.get('ê°€ê²©', 'ì •ë³´ ì—†ìŒ')}\\n\"\n",
    "            f\" - ì¬ë£Œ: {info.get('ì¬ë£Œ', 'ì •ë³´ ì—†ìŒ')}\\n\"\n",
    "            f\" - ì„¤ëª…: {info.get('ì„¤ëª…', 'ì •ë³´ ì—†ìŒ')}\"\n",
    "        )\n",
    "    return {\"messages\": [AIMessage(content=response)]}\n",
    "\n",
    "def handle_price_inquiry(state: MessageState) -> dict:\n",
    "    \"\"\"ê°€ê²© ê´€ë ¨ ë¬¸ì˜ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.\"\"\"\n",
    "    user_message = state[\"messages\"][-1].content\n",
    "    # ì‚¬ìš©ì ë©”ì‹œì§€ë¡œ ê²€ìƒ‰í•˜ì—¬ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë©”ë‰´ì˜ ê°€ê²©ì„ ë³´ì—¬ì¤Œ\n",
    "    docs = menu_db.similarity_search(user_message, k=1)\n",
    "    \n",
    "    if not docs:\n",
    "        response = \"ì£„ì†¡í•©ë‹ˆë‹¤, ë¬¸ì˜í•˜ì‹  ë©”ë‰´ì˜ ê°€ê²© ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    else:\n",
    "        info = parse_menu_doc(docs[0])\n",
    "        response = f\"âœ… {info.get('ë©”ë‰´', 'í•´ë‹¹ ë©”ë‰´')}ì˜ ê°€ê²©ì€ {info.get('ê°€ê²©', 'ì •ë³´ ì—†ìŒ')}ì…ë‹ˆë‹¤.\"\n",
    "    \n",
    "    return {\"messages\": [AIMessage(content=response)]}\n",
    "\n",
    "def handle_recommendation_request(state: MessageState) -> dict:\n",
    "    \"\"\"ë©”ë‰´ ì¶”ì²œ ìš”ì²­ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.\"\"\"\n",
    "    user_message = state[\"messages\"][-1].content\n",
    "    # ì‚¬ìš©ì ë©”ì‹œì§€ + ê¸°ë³¸ ì¶”ì²œ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰\n",
    "    docs = menu_db.similarity_search(user_message, k=3)\n",
    "    if not docs:\n",
    "        docs = menu_db.similarity_search(\"ì¸ê¸° ìˆëŠ” ë©”ë‰´\", k=3)\n",
    "\n",
    "    response_parts = [\"âœ… ì´ëŸ° ë©”ë‰´ëŠ” ì–´ë– ì„¸ìš”?\"]\n",
    "    for doc in docs:\n",
    "        info = parse_menu_doc(doc)\n",
    "        response_parts.append(f\" - **{info.get('ë©”ë‰´')}**: {info.get('ì„¤ëª…')}\")\n",
    "        \n",
    "    return {\"messages\": [AIMessage(content=\"\\n\".join(response_parts))]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac89783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraph ê·¸ë˜í”„ ìƒì„± \n",
    "\n",
    "# MessageStateë¥¼ ìƒíƒœë¡œ ì‚¬ìš©í•˜ëŠ” ê·¸ë˜í”„ ì •ì˜\n",
    "graph = StateGraph(MessageState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "graph.add_node(\"menu_inquiry\", handle_menu_inquiry)\n",
    "graph.add_node(\"price_inquiry\", handle_price_inquiry)\n",
    "graph.add_node(\"recommendation_request\", handle_recommendation_request)\n",
    "\n",
    "# ì‹œì‘ì  ì„¤ì •\n",
    "graph.set_entry_point(\"classify_question\")\n",
    "\n",
    "# ì¡°ê±´ë¶€ ì—£ì§€(Edge) ì„¤ì •: ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œë¡œ ë¶„ê¸°\n",
    "graph.add_conditional_edges(\n",
    "    \"classify_question\",\n",
    "    classify_question,\n",
    "    {\n",
    "        \"menu_inquiry\": \"menu_inquiry\",\n",
    "        \"price_inquiry\": \"price_inquiry\",\n",
    "        \"recommendation_request\": \"recommendation_request\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# ê° ì²˜ë¦¬ ë…¸ë“œ ì´í›„ì—ëŠ” ê·¸ë˜í”„ë¥¼ ì¢…ë£Œ\n",
    "graph.add_edge(\"menu_inquiry\", END)\n",
    "graph.add_edge(\"price_inquiry\", END)\n",
    "graph.add_edge(\"recommendation_request\", END)\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "app = graph.compile()\n",
    "\n",
    "def run_chatbot(question: str, thread_id: str):\n",
    "    \"\"\"ì§€ì •ëœ ìŠ¤ë ˆë“œì—ì„œ ì±—ë´‡ì„ ì‹¤í–‰í•˜ê³  ì‘ë‹µì„ ì¶œë ¥í•©ë‹ˆë‹¤.\"\"\"\n",
    "    print(f\"\\nğŸ‘¤ User: {question}\")\n",
    "    \n",
    "    # ëŒ€í™” ì´ë ¥ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ thread_id ì‚¬ìš©\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    \n",
    "    # HumanMessage ê°ì²´ë¡œ ì…ë ¥\n",
    "    input_message = [HumanMessage(content=question)]\n",
    "    \n",
    "    # ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì‘ë‹µ ë°›ê¸°\n",
    "    response_stream = app.stream(input=input_message, config=config)\n",
    "    \n",
    "    full_response = \"\"\n",
    "    print(\"ğŸ¤– AI: \", end=\"\")\n",
    "    for chunk in response_stream:\n",
    "        # ë§ˆì§€ë§‰ ë‹¨ê³„ì˜ AI ë©”ì‹œì§€ë§Œ ì¶œë ¥\n",
    "        last_message = next(iter(chunk.values()))[\"messages\"][-1]\n",
    "        if isinstance(last_message, AIMessage):\n",
    "            print(last_message.content, end=\"\")\n",
    "            full_response += last_message.content\n",
    "    print()\n",
    "\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "thread_id = \"cafe-thread-1\" # ëŒ€í™” ì„¸ì…˜ì„ ì‹ë³„í•˜ëŠ” ID\n",
    "run_chatbot(\"ì•ˆë…•í•˜ì„¸ìš”!\", thread_id)\n",
    "run_chatbot(\"ì½œë“œë¸Œë£¨ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.\", thread_id)\n",
    "run_chatbot(\"ì¹˜ì¦ˆì¼€ì´í¬ëŠ” ì–¼ë§ˆì¸ê°€ìš”?\", thread_id)\n",
    "run_chatbot(\"ë‹¬ë‹¬í•œ ìŒë£Œ ì¶”ì²œí•´ì¤˜.\", thread_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python mylangchain-app",
   "language": "python",
   "name": "mylangchain-app"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
