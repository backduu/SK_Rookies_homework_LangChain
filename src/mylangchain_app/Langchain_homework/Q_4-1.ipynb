{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "507517bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문제 4-1 : 카페 메뉴 도구(Tool) 호출 체인 구현 ( LangChain 사용)\n"
     ]
    }
   ],
   "source": [
    "print(\"문제 4-1 : 카페 메뉴 도구(Tool) 호출 체인 구현 ( LangChain 사용)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2362da8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs\n",
      "3g\n",
      "tv\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])\n",
    "print(UPSTAGE_API_KEY[30:])\n",
    "print(TAVILY_API_KEY[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "861b77e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x0000025E0C085A90> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025E0C0868A0> model_name='solar-pro' temperature=0.5 model_kwargs={} upstage_api_key=SecretStr('**********') upstage_api_base='https://api.upstage.ai/v1'\n"
     ]
    }
   ],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "llm = ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        temperature=0.5\n",
    "    )\n",
    "print(llm)\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# llm = ChatOpenAI(\n",
    "#     model='gpt-3.5-turbo-0125', \n",
    "#     temperature=0,\n",
    "# )\n",
    "# print(llm.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03e4395e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터 DB가 './db/cafe_db_upstage' 폴더에 성공적으로 생성 및 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# 데이터 로드 및 분할\n",
    "\n",
    "loader = TextLoader(\"./data/cafe_menu.txt\", encoding=\"utf-8\")\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# 벡터 DB 생성 및 저장\n",
    "\n",
    "embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "db.save_local(\"./db/cafe_db_upstage\")\n",
    "\n",
    "print(\"벡터 DB가 './db/cafe_db_upstage' 폴더에 성공적으로 생성 및 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1808e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_upstage import ChatUpstage \n",
    "\n",
    "# Tavily 웹 검색 도구\n",
    "tavily_search_func = TavilySearchResults(max_results=1, name=\"tavily_search_tool\")\n",
    "\n",
    "# 위키피디아 검색 및 요약 도구\n",
    "@tool\n",
    "def wiki_summary(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches Wikipedia for the given query and returns a summary of the top result.\n",
    "    Use this tool for general knowledge questions about topics, people, concepts, etc.\n",
    "    \"\"\"\n",
    "    wiki_client = WikipediaAPIWrapper()\n",
    "    return wiki_client.run(query)\n",
    "\n",
    "# 로컬 카페 메뉴 DB 검색 도구 \n",
    "@tool\n",
    "def db_search_cafe_func(query: str) -> list:\n",
    "    \"\"\"\n",
    "    Searches the local cafe menu vector database for information about menu items,\n",
    "    including their price, ingredients, and description. Use this for any questions\n",
    "    related to the cafe's menu.\n",
    "    \"\"\"\n",
    "    embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "    db = FAISS.load_local(\"./db/cafe_db_upstage\", embeddings, allow_dangerous_deserialization=True)\n",
    "    retriever = db.as_retriever(search_kwargs={\"k\": 2})\n",
    "    \n",
    "    result_docs = retriever.invoke(query)\n",
    "    return [doc.page_content for doc in result_docs]\n",
    "\n",
    "tools = [tavily_search_func, wiki_summary, db_search_cafe_func]\n",
    "llm = ChatUpstage(model=\"solar-1-mini-chat\", temperature=0) \n",
    "llm_with_tools = llm.bind_tools(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3146742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "\n",
    "@chain\n",
    "def tool_chain(user_input: str):\n",
    "    ai_msg: AIMessage = llm_with_tools.invoke([HumanMessage(content=user_input)])\n",
    "\n",
    "    if not ai_msg.tool_calls:\n",
    "        return ai_msg.content\n",
    "\n",
    "    tool_msgs = []\n",
    "    for call in ai_msg.tool_calls:\n",
    "        tool_name = call[\"name\"]\n",
    "        args = call[\"args\"]\n",
    "        for t in tools:\n",
    "            if t.name == tool_name:\n",
    "                result = t.invoke(args[\"query\"])\n",
    "                tool_msgs.append(\n",
    "                    ToolMessage(content=str(result), tool_call_id=call[\"id\"])\n",
    "                )\n",
    "\n",
    "    final_response = llm_with_tools.invoke(\n",
    "        [HumanMessage(content=user_input), ai_msg, *tool_msgs]\n",
    "    )\n",
    "    return final_response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a49675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 아메리카노의 가격과 특징은 무엇인가요?\n",
      "답변: 아메리카노의 가격은 ₩4,500이며, 주요 원료는 에스프레소와 뜨거운 물입니다. 아메리카노는 진한 에스프레소에 뜨거운 물을 더해 만든 클래식한 블랙 커피로, 원두 본연의 맛을 가장 잘 느낄 수 있으며, 깔끔하고 깊은 풍미가 특징입니다. 설탕이나 시럽 추가가 가능합니다. 또한, 아이스 아메리카노도 있으며, 가격은 ₩4,500입니다. 아이스 아메리카노는 진한 에스프레소에 차가운 물과 얼음을 넣어 만든 시원한 아이스 커피로, 깔끔하고 시원한 맛이 특징이며, 더운 날씨에 인기가 높습니다.\n"
     ]
    }
   ],
   "source": [
    "# 테스트 질문 실행\n",
    "question = \"아메리카노의 가격과 특징은 무엇인가요?\"\n",
    "\n",
    "response = tool_chain.invoke(question)\n",
    "\n",
    "print(f\"질문: {question}\")\n",
    "print(f\"답변: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
